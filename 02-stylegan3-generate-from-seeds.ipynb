{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.], device='mps:0')\n"]},{"name":"stderr","output_type":"stream","text":["/Users/ted/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/_tensor_str.py:137: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:335.)\n","  nonzero_finite_vals = torch.masked_select(\n"]}],"source":["import torch\n","if torch.backends.mps.is_available():\n","    mps_device = torch.device(\"mps\")\n","    x = torch.ones(1, device=mps_device)\n","    print (x)\n","else:\n","    print (\"MPS device not found.\")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21613,"status":"ok","timestamp":1716643086033,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"WbCGexOebBGi","outputId":"8991a486-0733-42db-9c6a-69134e5870c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# https://www.linkedin.com/pulse/how-use-gpu-tensorflow-pytorch-libraries-macbook-pro-m2apple-kashyap/\n","\n","# Connect Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Vn5kRZG8cZFl"},"source":["# StyleGAN3 from NVIDIA\n","\n","**Notes**\n","* To see the original code from NVIDIA [Check here](https://github.com/NVlabs/stylegan3)\n","* We are using a pretrained model and fine-tuning on top of it.\n","* If you come across bugs please post them in [Discord](https://discord.com/invite/awREd7EtMA)\n","\n","---\n","\n","If you find this notebook useful, consider signing up for my [Code Sprout Newsletter](https://codesprout.substack.com/welcome) or [Check my links](https://shyambv.bio.link/)\n","\n","Medium article related to it is mentioned []()"]},{"cell_type":"markdown","metadata":{"id":"L4Y28xIshBYs"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150894,"status":"ok","timestamp":1716643236925,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"jL6aLWrr4zl8","outputId":"42649aa1-ff98-40bb-c8a4-2a203f7109f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch==1.13.0\n","  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0) (4.11.0)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.43.0)\n","Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 1.13.0 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.13.0 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n"]}],"source":["# !pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n","!pip install torch==1.13.0\n","# torchvision torchaudio -f https://download.pytorch.org/whl/cu113/torch_stable.html\n","!pip install setuptools"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15465,"status":"ok","timestamp":1716643252377,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"APfJ_U0vx1rH","outputId":"96396d49-bf9e-40f3-ffb7-9cebc54949f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m897.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ninja\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n","Collecting torch_utils\n","  Downloading torch-utils-0.1.2.tar.gz (4.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch_utils) (1.13.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch_utils) (4.11.0)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->torch_utils) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->torch_utils) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->torch_utils) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->torch_utils) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torch_utils) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torch_utils) (0.43.0)\n","Building wheels for collected packages: torch_utils\n","  Building wheel for torch_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch_utils: filename=torch_utils-0.1.2-py3-none-any.whl size=6186 sha256=07ab98df650e042786b02bf17c4436ef78dc83a88cf0c5e313a417b7287957aa\n","  Stored in directory: /root/.cache/pip/wheels/76/08/f0/378d1fe4aac5aa1e21483918d70b7e3428c4faaac0abda4e15\n","Successfully built torch_utils\n","Installing collected packages: ninja, einops, torch_utils\n","Successfully installed einops-0.8.0 ninja-1.11.1.1 torch_utils-0.1.2\n"]}],"source":["!pip install einops ninja gdown torch_utils"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1716643252378,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"00S7pPSdhZ5g","outputId":"7e543059-7e75-4056-deff-23faa4ceb44c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/WIP/stylegan3\n"]}],"source":["import os\n","if os.path.isdir('/content/drive/MyDrive/WIP/stylegan3/'):\n","    %cd '/content/drive/MyDrive/WIP/stylegan3/'\n","else:\n","    # !git clone https://github.com/bvshyam/stylegan3.git /content/drive/MyDrive/WIP/stylegan3/\n","    %cd '/content/drive/MyDrive/WIP/stylegan3/'\n"]},{"cell_type":"markdown","metadata":{"id":"tYw4XWfXhgWk"},"source":["# Generate images"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1716643252378,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"VrSWGWIjykbE"},"outputs":[],"source":["#model_path = '/content/drive/MyDrive/WIP/stylegan3/results/00002-stylegan3-t-artimages-512x512-gpus1-batch16-gamma50/network-snapshot-000001.pkl'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1716643252378,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"lYsuiuwIykhn"},"outputs":[],"source":["#Random generation of images using model created\n","\n","#!python /content/drive/MyDrive/WIP/stylegan3/gen_images.py --outdir=out --trunc=1 --seeds=40 \\\n","    # --network=$model_path"]},{"cell_type":"markdown","metadata":{"id":"ZbGxtqncL0dN"},"source":["Check-out other articles [Medium](https://bvshyam.medium.com/)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4331,"status":"ok","timestamp":1716643256693,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"wZ5c1kq6yoAK"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/ted/dev/stylegan3/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n"]}],"source":["import torch\n","import pickle\n","import os\n","import PIL.Image\n","from IPython.display import Image\n","import matplotlib.pyplot as plt\n","import IPython.display\n","\n","\"\"\"Generate images using pretrained network pickle.\"\"\"\n","\n","import os\n","import re\n","from typing import List, Optional, Tuple, Union\n","\n","import click\n","import dnnlib\n","import numpy as np\n","import PIL.Image\n","import torch\n","\n","import legacy\n","\n","from pathlib import Path\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":12593,"status":"error","timestamp":1716643269282,"user":{"displayName":"Ted Moore","userId":"02111902761679680911"},"user_tz":240},"id":"XIb-g1Sk1z-R","outputId":"4e655df1-e2b6-4932-c00c-c0c61245fab5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading networks from \"/Users/ted/dev/stylegan3/00022-stylegan3-r-240523_01-rose01-YFlips-6min-gpus1-batch8-gamma6.6/network-snapshot-000072.pkl\"...\n","0 / 500\t/Volumes/2024-May-Ted-Moore/videos/rose/stylegan/240525_02-roseYFlips-seeds-1000-1499-pkl=72/seed1000.png\n","1 / 500\t/Volumes/2024-May-Ted-Moore/videos/rose/stylegan/240525_02-roseYFlips-seeds-1000-1499-pkl=72/seed1001.png\n","2 / 500\t/Volumes/2024-May-Ted-Moore/videos/rose/stylegan/240525_02-roseYFlips-seeds-1000-1499-pkl=72/seed1002.png\n","3 / 500\t/Volumes/2024-May-Ted-Moore/videos/rose/stylegan/240525_02-roseYFlips-seeds-1000-1499-pkl=72/seed1003.png\n","4 / 500\t/Volumes/2024-May-Ted-Moore/videos/rose/stylegan/240525_02-roseYFlips-seeds-1000-1499-pkl=72/seed1004.png\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 134\u001b[0m\n\u001b[1;32m    131\u001b[0m     m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(m)\n\u001b[1;32m    132\u001b[0m     G\u001b[38;5;241m.\u001b[39msynthesis\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(m))\n\u001b[0;32m--> 134\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation_psi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_psi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m img \u001b[38;5;241m=\u001b[39m (img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    136\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outdir,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m<string>:512\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, z, c, truncation_psi, truncation_cutoff, update_emas, **synthesis_kwargs)\u001b[0m\n","File \u001b[0;32m~/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m<string>:471\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, ws, **layer_kwargs)\u001b[0m\n","File \u001b[0;32m~/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m<string>:355\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, w, noise_mode, force_fp32, update_emas)\u001b[0m\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/ops/filtered_lrelu.py:116\u001b[0m, in \u001b[0;36mfiltered_lrelu\u001b[0;34m(x, fu, fd, b, up, down, padding, gain, slope, clamp, flip_filter, impl)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impl \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _init():\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _filtered_lrelu_cuda(up\u001b[38;5;241m=\u001b[39mup, down\u001b[38;5;241m=\u001b[39mdown, padding\u001b[38;5;241m=\u001b[39mpadding, gain\u001b[38;5;241m=\u001b[39mgain, slope\u001b[38;5;241m=\u001b[39mslope, clamp\u001b[38;5;241m=\u001b[39mclamp, flip_filter\u001b[38;5;241m=\u001b[39mflip_filter)\u001b[38;5;241m.\u001b[39mapply(x, fu, fd, b, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filtered_lrelu_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdown\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflip_filter\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/misc.py:103\u001b[0m, in \u001b[0;36mprofiled_function.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/ops/filtered_lrelu.py:146\u001b[0m, in \u001b[0;36m_filtered_lrelu_ref\u001b[0;34m(x, fu, fd, b, up, down, padding, gain, slope, clamp, flip_filter)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Compute using existing ops.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m x \u001b[38;5;241m=\u001b[39m bias_act\u001b[38;5;241m.\u001b[39mbias_act(x\u001b[38;5;241m=\u001b[39mx, b\u001b[38;5;241m=\u001b[39mb) \u001b[38;5;66;03m# Apply bias.\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mupfirdn2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupfirdn2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflip_filter\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Upsample.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m x \u001b[38;5;241m=\u001b[39m bias_act\u001b[38;5;241m.\u001b[39mbias_act(x\u001b[38;5;241m=\u001b[39mx, act\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39mslope, gain\u001b[38;5;241m=\u001b[39mgain, clamp\u001b[38;5;241m=\u001b[39mclamp) \u001b[38;5;66;03m# Bias, leaky ReLU, clamp.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m x \u001b[38;5;241m=\u001b[39m upfirdn2d\u001b[38;5;241m.\u001b[39mupfirdn2d(x\u001b[38;5;241m=\u001b[39mx, f\u001b[38;5;241m=\u001b[39mfd, down\u001b[38;5;241m=\u001b[39mdown, flip_filter\u001b[38;5;241m=\u001b[39mflip_filter) \u001b[38;5;66;03m# Downsample.\u001b[39;00m\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/ops/upfirdn2d.py:162\u001b[0m, in \u001b[0;36mupfirdn2d\u001b[0;34m(x, f, up, down, padding, flip_filter, gain, impl)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impl \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _init():\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _upfirdn2d_cuda(up\u001b[38;5;241m=\u001b[39mup, down\u001b[38;5;241m=\u001b[39mdown, padding\u001b[38;5;241m=\u001b[39mpadding, flip_filter\u001b[38;5;241m=\u001b[39mflip_filter, gain\u001b[38;5;241m=\u001b[39mgain)\u001b[38;5;241m.\u001b[39mapply(x, f)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_upfirdn2d_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdown\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflip_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/misc.py:103\u001b[0m, in \u001b[0;36mprofiled_function.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/ops/upfirdn2d.py:207\u001b[0m, in \u001b[0;36m_upfirdn2d_ref\u001b[0;34m(x, f, up, down, padding, flip_filter, gain)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv2d_gradfix\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mx, weight\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m), groups\u001b[38;5;241m=\u001b[39mnum_channels)\n\u001b[0;32m--> 207\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv2d_gradfix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_channels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Downsample by throwing away pixels.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, :, ::downy, ::downx]\n","File \u001b[0;32m~/dev/stylegan3/stylegan3/torch_utils/ops/conv2d_gradfix.py:40\u001b[0m, in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_use_custom_op(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _conv2d_gradfix(transpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, weight_shape\u001b[38;5;241m=\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape, stride\u001b[38;5;241m=\u001b[39mstride, padding\u001b[38;5;241m=\u001b[39mpadding, output_padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dilation\u001b[38;5;241m=\u001b[39mdilation, groups\u001b[38;5;241m=\u001b[39mgroups)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28minput\u001b[39m, weight, bias)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# model_path = '/content/drive/MyDrive/dev/arco/training/00021-stylegan3-r-rose01-blobs-square-gpus1-batch8-gamma6.6/network-snapshot-000160.pkl'\n","model_path = '/Users/ted/dev/stylegan3/00022-stylegan3-r-240523_01-rose01-YFlips-6min-gpus1-batch8-gamma6.6/network-snapshot-000072.pkl'\n","outdir = '/Volumes/2024-May-Ted-Moore/videos/rose/stylegan/240525_02-roseYFlips-seeds-1000-1499-pkl=72'\n","\n","torch.device('mps')\n","#----------------------------------------------------------------------------\n","\n","assert os.path.isfile(model_path)\n","\n","with open(model_path, 'rb') as f:\n","    G = pickle.load(f)['G_ema'].to(mps_device) #cuda()  # torch.nn.Module\n","\n","def parse_range(s: Union[str, List]) -> List[int]:\n","    '''Parse a comma separated list of numbers or ranges and return a list of ints.\n","    Example: '1,2,5-10' returns [1, 2, 5, 6, 7]\n","    '''\n","    if isinstance(s, list): return s\n","    ranges = []\n","    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n","    for p in s.split(','):\n","        m = range_re.match(p)\n","        if m:\n","            ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n","        else:\n","            ranges.append(int(p))\n","    return ranges\n","\n","#----------------------------------------------------------------------------\n","\n","def parse_vec2(s: Union[str, Tuple[float, float]]) -> Tuple[float, float]:\n","    '''Parse a floating point 2-vector of syntax 'a,b'.\n","    Example:\n","        '0,1' returns (0,1)\n","    '''\n","    if isinstance(s, tuple): return s\n","    parts = s.split(',')\n","    if len(parts) == 2:\n","        return (float(parts[0]), float(parts[1]))\n","    raise ValueError(f'cannot parse 2-vector {s}')\n","\n","#----------------------------------------------------------------------------\n","\n","def make_transform(translate: Tuple[float,float], angle: float):\n","    m = np.eye(3)\n","    s = np.sin(angle/360.0*np.pi*2)\n","    c = np.cos(angle/360.0*np.pi*2)\n","    m[0][0] = c\n","    m[0][1] = s\n","    m[0][2] = translate[0]\n","    m[1][0] = -s\n","    m[1][1] = c\n","    m[1][2] = translate[1]\n","    return m\n","\n","#----------------------------------------------------------------------------\n","\n","# @click.command()\n","# @click.option('--network', 'network_pkl', help='Network pickle filename', required=True)\n","# @click.option('--seeds', type=parse_range, help='List of random seeds (e.g., \\'0,1,4-6\\')', required=True)\n","# @click.option('--trunc', 'truncation_psi', type=float, help='Truncation psi', default=1, show_default=True)\n","# @click.option('--class', 'class_idx', type=int, help='Class label (unconditional if not specified)')\n","# @click.option('--noise-mode', help='Noise mode', type=click.Choice(['const', 'random', 'none']), default='const', show_default=True)\n","# @click.option('--translate', help='Translate XY-coordinate (e.g. \\'0.3,1\\')', type=parse_vec2, default='0,0', show_default=True, metavar='VEC2')\n","# @click.option('--rotate', help='Rotation angle in degrees', type=float, default=0, show_default=True, metavar='ANGLE')\n","# @click.option('--outdir', help='Where to save the output images', type=str, required=True, metavar='DIR')\n","# def generate_images(\n","#     network_pkl: str,\n","#     seeds: List[int],\n","#     truncation_psi: float,\n","#     noise_mode: str,\n","#     outdir: str,\n","#     translate: Tuple[float,float],\n","#     rotate: float,\n","#     class_idx: Optional[int]\n","# ):\n","\"\"\"Generate images using pretrained network pickle.\n","Examples:\n","\\b\n","# Generate an image using pre-trained AFHQv2 model (\"Ours\" in Figure 1, left).\n","python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\\\n","    --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\n","\\b\n","# Generate uncurated images with truncation using the MetFaces-U dataset\n","python gen_images.py --outdir=out --trunc=0.7 --seeds=600-605 \\\\\n","    --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfacesu-1024x1024.pkl\n","\"\"\"\n","\n","# =============== setting params manually instead of with click ==================\n","class_idx = None\n","translate = (0,0)\n","noise_mode = 'const'\n","rotate = 0\n","truncation_psi = 1\n","# ================================================================================\n","\n","Path(outdir).mkdir(exist_ok=True)\n","\n","print('Loading networks from \"%s\"...' % model_path)\n","device = torch.device('mps')\n","with dnnlib.util.open_url(model_path) as f:\n","    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n","\n","# os.makedirs(outdir, exist_ok=True)\n","\n","# Labels.\n","label = torch.zeros([1, G.c_dim], device=device)\n","if G.c_dim != 0:\n","    if class_idx is None:\n","        raise click.ClickException('Must specify class label with --class when using a conditional network')\n","    label[:, class_idx] = 1\n","else:\n","    if class_idx is not None:\n","        print ('warn: --class=lbl ignored when running on an unconditional network')\n","\n","\n","# Generate images.\n","seeds_start = 1000\n","n_seeds = 500\n","\n","for i, seed in enumerate(range(seeds_start,seeds_start + n_seeds)):\n","    # print('Generating image for seed %d (%d/%d) ...' % (seed, seed_idx, len(seeds)))\n","    z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(torch.float32).to(device)\n","    # print(z.shape)\n","    # print(z)\n","\n","    # Construct an inverse rotation/translation matrix and pass to the generator.  The\n","    # generator expects this matrix as an inverse to avoid potentially failing numerical\n","    # operations in the network.\n","    if hasattr(G.synthesis, 'input'):\n","        m = make_transform(translate, rotate)\n","        m = np.linalg.inv(m)\n","        G.synthesis.input.transform.copy_(torch.from_numpy(m))\n","\n","    img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n","    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n","    save_path = os.path.join(outdir,f'seed{seed:04d}.png')\n","    PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(save_path)\n","\n","    print(f'{i} / {n_seeds}\\t{save_path}')\n","\n","    # display:\n","    # plt.axis('off')\n","    # img = img.reshape((img.shape[1],img.shape[2],img.shape[3]))\n","    # plt.imshow(img.cpu())\n","    # plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1Nal3M-wjv6BeIgyTgvxhaccPFGEP6cbk","timestamp":1675278682956}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
